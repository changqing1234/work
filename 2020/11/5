今天找了一篇c会的论文，(ICPADS 2019）
Understanding Distributed Poisoning Attack in Federated Learning
论文通过对联邦学习系统进行投毒攻击，分析了投毒样本数量和攻击者数量如何影响投毒攻击的性能，攻击成功率与投毒样本数量成线性关系。。论文也提出了一种防御方案Sniper，
消除训练过程中恶意参与者的投毒本地模型。通过观察模型之间的距离，将诚实用户和攻击者的模型分成不同的派系。
论文的思路是计算模型之间的欧几里得距离，然后分成有毒和无毒模型。

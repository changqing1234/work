上数据库网课
今天在看师兄给的论文《Local Model Poisoning Attacks to Byzantine-Robust Federated Learning 》
论文也是攻击联邦学习，针对机器学习社区的提出的联邦学习方法，作者提出攻击方法，论文假设了敌手已经攻击了某些客户端，通过操纵
这些客户端的模型数据，使得全局的模型错误率增大，使得最终的模型可用性降低。论文也提出了两种防御措施。

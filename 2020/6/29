今天看了一篇联邦学习中的后门攻击论文How to backdoor federated learning。
论文设计一种新的基于模型替换的模型中毒方法。在一轮联邦学习中被选中的攻击者可以使全局模型在后门任务上立即达到100%的准确性。
只需要控制1%的客户端就可以完成后门攻击。在主任务精度很高的同时，可以让攻击者的子任务的精度也很高。
上次师兄发给我的TIFS论文的防御方案就是针对这个攻击轮文的。
